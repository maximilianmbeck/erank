{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "sys.path.append('..')\n",
    "# sys.path.append('/system/user/beck/pwbeck/projects/regularization/ml_utilities')\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from pprint import pprint\n",
    "from ml_utilities.torch_models.base_model import BaseModel\n",
    "from ml_utilities.torch_models.fc import FC\n",
    "from ml_utilities.torch_models import get_model_class\n",
    "from ml_utilities.output_loader.repo import Repo\n",
    "from ml_utilities.output_loader.job_output import JobResult, SweepResult\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from erank.data.datasetgenerator import DatasetGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "gpu_id = 0\n",
    "REPO = Repo(dir=Path('../../erank'), hydra_defaults=OmegaConf.load('../configs/hydra/jobname_outputdir_format.yaml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear interpolation debug notebook\n",
    "This notebook is used to implement linear interplation of models. \n",
    "\n",
    "Do linear interpolation with on MNIST. Use data from Experiment 11.7.3. \n",
    "\n",
    "Start from pretrained model with 100 steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml = \"\"\"\n",
    "run_config:\n",
    "  exec_type: parallel # sequential\n",
    "  hostname: gorilla\n",
    "  gpu_ids: [0,1,2,3,4,5,6,7]\n",
    "  runs_per_gpu: 3\n",
    "\n",
    "  wandb: # wandb config for run_handler, if \"wandb: null\" then logging to wandb is disabled for run_handler\n",
    "    init:\n",
    "      tags:\n",
    "        - ${config.experiment_data.experiment_tag}_exps\n",
    "        - run_handler\n",
    "      notes: #\n",
    "      group: ${config.experiment_data.experiment_tag}\n",
    "      job_type: run_handler\n",
    "\n",
    "seeds: [1,2,3]\n",
    "\n",
    "sweep:\n",
    "  type: grid\n",
    "  axes:\n",
    "    - parameter: trainer.init_model_step\n",
    "      vals: [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475]\n",
    "    - parameter: data.dataset_kwargs.rotation_angle\n",
    "      vals: linspace(0,180,50,endpoint=True)\n",
    "    - parameter: data.dataset_split.restrict_n_samples_train_task\n",
    "      vals: [300] #[5, 20, 50, 100, 500, 1000, 10000, 48000]\n",
    "\n",
    "start_num: 3 # use this to count how often this config is run\n",
    "###\n",
    "config:\n",
    "  experiment_data:\n",
    "    entity: jkuiml-fsl\n",
    "    project_name: sparsity\n",
    "    experiment_tag: \"11.7\"\n",
    "    experiment_type: startnum_${start_num}\n",
    "    experiment_name: mnist-${config.experiment_data.experiment_tag}.${start_num}-lenet_rottasks_ft\n",
    "    experiment_dir: null\n",
    "    experiment_notes: Hyperparameter search.\n",
    "    job_name: null\n",
    "    seed: 0\n",
    "    hostname: null # the server on which the run is run, will be filled by run_handler\n",
    "    gpu_id: 0\n",
    "\n",
    "  # wandb:\n",
    "  #   init:\n",
    "  #     tags: # list(), used to tag wandblogger\n",
    "  #       - ${config.experiment_data.experiment_tag}_exps\n",
    "  #     notes: ${config.experiment_data.experiment_notes} # str, used to make notes to wandblogger\n",
    "  #     group: ${config.experiment_data.experiment_tag} # null\n",
    "  #     job_type: ${config.experiment_data.experiment_type} # examples: hypsearch, pretrain, eval, etc.\n",
    "\n",
    "  #   watch:\n",
    "  #     log: null #parameters #null #all\n",
    "  #     log_freq: 5000\n",
    "\n",
    "  model:\n",
    "    name: fc\n",
    "    model_kwargs:\n",
    "      input_size: 784\n",
    "      hidden_sizes:\n",
    "        - 300\n",
    "        - 100\n",
    "      output_size: 10\n",
    "      flatten_input: True\n",
    "      dropout: null\n",
    "      act_fn: relu\n",
    "\n",
    "  trainer:\n",
    "    training_setup: supervised\n",
    "    n_steps: 2000\n",
    "    log_train_step_every: 1\n",
    "    log_additional_train_step_every_multiplier: 1\n",
    "    log_additional_logs: True\n",
    "    val_every: 5\n",
    "    save_every: 5 #500\n",
    "    early_stopping_patience: 200 #500\n",
    "    batch_size: 128\n",
    "    optimizer_scheduler:\n",
    "      optimizer_name: adamw #sgd #adamw\n",
    "      optimizer_kwargs:\n",
    "        lr: 0.001\n",
    "        weight_decay: 0.0\n",
    "    \n",
    "    init_model_step: XXX\n",
    "    init_model: /system/user/beck/pwbeck/projects/regularization/erank/outputs/mnist-11.5.0-lenet--221015_122552/model_step_${config.trainer.init_model_step}.p\n",
    "\n",
    "    loss: crossentropy\n",
    "\n",
    "    metrics:\n",
    "      - Accuracy\n",
    "    num_workers: 4\n",
    "    verbose: False\n",
    "\n",
    "  data:\n",
    "    dataset: rotatedvision\n",
    "    dataset_kwargs:\n",
    "      data_root_path: /system/user/beck/pwbeck/data\n",
    "      dataset: mnist\n",
    "      rotation_angle: XXX\n",
    "    dataset_split:\n",
    "      train_val_split: 0.8\n",
    "      restrict_n_samples_train_task: XXX\n",
    "\n",
    "\"\"\"\n",
    "cfg = OmegaConf.create(config_yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp. Tag(start_num): 11.7(3)\n",
      "Exp. Name: mnist-11.7.3-lenet_rottasks_ft\n",
      "Training setup: supervised\n",
      "Model name: fc\n",
      "Dataset name: rotatedvision\n",
      "Sweep type: grid\n",
      "  trainer.init_model_step: [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475]\n",
      "  data.dataset_kwargs.rotation_angle: linspace(0,180,50,endpoint=True)\n",
      "  data.dataset_split.restrict_n_samples_train_task: [300]\n",
      "Num. jobs: 5400\n",
      "Config updated: 2022-11-25 12:34:14\n",
      "Sweep started:  2022-11-25 12:36:51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sweepr = REPO.get_output_loader(cfg)\n",
    "print(sweepr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw_summary = sweepr.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pv_df = sw_summary[(sw_summary['trainer.init_model_step'] == 100) & sw_summary['data.dataset_kwargs.rotation_angle'].between(0,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pv_df.sort_values(by=['data.dataset_kwargs.rotation_angle', 'seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/system/user/publicwork/beck/projects/regularization/erank/outputs/mnist-11.7.3-lenet_rottasks_ft--221125_123651/outputs/mnist-11.7.3-lenet_rottasks_ft--init_model_step-100-rotation_angle-25.7143-restrict_n_samples_train_task-300-seed-2--221127_232024',\n",
       " '/system/user/publicwork/beck/projects/regularization/erank/outputs/mnist-11.7.3-lenet_rottasks_ft--221125_123651/outputs/mnist-11.7.3-lenet_rottasks_ft--init_model_step-100-rotation_angle-25.7143-restrict_n_samples_train_task-300-seed-3--221126_021736',\n",
       " '/system/user/publicwork/beck/projects/regularization/erank/outputs/mnist-11.7.3-lenet_rottasks_ft--221125_123651/outputs/mnist-11.7.3-lenet_rottasks_ft--init_model_step-100-rotation_angle-25.7143-restrict_n_samples_train_task-300-seed-1--221125_232309']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweepr.find_jobs('init_model_step-100-rotation_angle-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_pretrainsteps100_rotangle25 = sweepr.get_jobs('init_model_step-100-rotation_angle-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best models trained by 3 different seeds \n",
    "# these should all be linear mode connected\n",
    "model_a = jobs_pretrainsteps100_rotangle25[0].best_model\n",
    "model_b = jobs_pretrainsteps100_rotangle25[1].best_model\n",
    "model_c = jobs_pretrainsteps100_rotangle25[2].best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FC(\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: values should not be the same\n",
    "# model_a.state_dict()['fc.1.weight'], model_b.state_dict()['fc.1.weight'] # check successful"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainer.init_model_step': 100,\n",
       " 'data.dataset_kwargs.rotation_angle': 25.714285714285715,\n",
       " 'data.dataset_split.restrict_n_samples_train_task': 300}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_pretrainsteps100_rotangle25[0].override_hpparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg = cfg.config.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OmegaConf.update(data_cfg, 'dataset_kwargs.rotation_angle', 25.714285714285715)\n",
    "OmegaConf.update(data_cfg, 'dataset_split.restrict_n_samples_train_task', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: rotatedvision\n",
      "dataset_kwargs:\n",
      "  data_root_path: /system/user/beck/pwbeck/data\n",
      "  dataset: mnist\n",
      "  rotation_angle: 25.714285714285715\n",
      "dataset_split:\n",
      "  train_val_split: 0.8\n",
      "  restrict_n_samples_train_task: 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(data_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_generator = DatasetGenerator(**data_cfg)\n",
    "ds_generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 12000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_generator.train_split), len(ds_generator.val_split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model interpolation finetuned from same checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from erank.mode_connectivity import interpolate_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_fn = nn.CrossEntropyLoss()\n",
    "# score_fn = torchmetrics.Accuracy()\n",
    "from ml_utilities.torch_utils.metrics import SimpleAccuracy\n",
    "score_fn = SimpleAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2000, 0.4000, 0.6000, 0.8000, 1.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.linspace(0, 1.0, 6)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interp. factors: 100%|██████████| 6/6 [00:23<00:00,  3.92s/it]\n",
      "{'__weights': [0.0,\n",
      "               0.20000000298023224,\n",
      "               0.4000000059604645,\n",
      "               0.6000000238418579,\n",
      "               0.800000011920929,\n",
      "               1.0],\n",
      " '_cosinesimilarity': 0.989238977432251,\n",
      " '_l2distance': 2.3759570121765137,\n",
      " 'val': [0.8735514879226685,\n",
      "         0.8734565377235413,\n",
      "         0.8736345767974854,\n",
      "         0.8736464977264404,\n",
      "         0.8737414479255676,\n",
      "         0.8745725750923157]}\n"
     ]
    }
   ],
   "source": [
    "res_dict = interpolate_linear(model_a, model_b, ds_generator.train_split, score_fn, weights, {'val': ds_generator.val_split})\n",
    "pprint(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: values should not be the same\n",
    "# model_a.state_dict()['fc.1.weight'], model_b.state_dict()['fc.1.weight'] # check successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interp. factors: 100%|██████████| 6/6 [00:21<00:00,  3.66s/it]\n",
      "{'__weights': [0.0,\n",
      "               0.20000000298023224,\n",
      "               0.4000000059604645,\n",
      "               0.6000000238418579,\n",
      "               0.800000011920929,\n",
      "               1.0],\n",
      " '_cosinesimilarity': 0.9810684323310852,\n",
      " '_l2distance': 3.155956268310547,\n",
      " 'val': [0.8735514879226685,\n",
      "         0.8740382790565491,\n",
      "         0.8744538426399231,\n",
      "         0.87546306848526,\n",
      "         0.8760923147201538,\n",
      "         0.8754274249076843]}\n"
     ]
    }
   ],
   "source": [
    "res_dict = interpolate_linear(model_a, model_c, ds_generator.train_split, score_fn, weights, {'val': ds_generator.val_split})\n",
    "pprint(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interp. factors: 100%|██████████| 6/6 [00:22<00:00,  3.67s/it]\n",
      "{'__weights': [0.0,\n",
      "               0.20000000298023224,\n",
      "               0.4000000059604645,\n",
      "               0.6000000238418579,\n",
      "               0.800000011920929,\n",
      "               1.0],\n",
      " '_cosinesimilarity': 0.9805640578269958,\n",
      " '_l2distance': 3.192615270614624,\n",
      " 'val': [0.8745725750923157,\n",
      "         0.875558078289032,\n",
      "         0.8773152828216553,\n",
      "         0.8768997192382812,\n",
      "         0.8761754035949707,\n",
      "         0.8754274249076843]}\n"
     ]
    }
   ],
   "source": [
    "res_dict = interpolate_linear(model_b, model_c, ds_generator.train_split, score_fn, weights, {'val': ds_generator.val_split})\n",
    "pprint(res_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model interpolation independently trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml2 = \"\"\"\n",
    "run_config:\n",
    "  exec_type: parallel # sequential\n",
    "  hostname: raptor\n",
    "  gpu_ids: [0]\n",
    "  runs_per_gpu: 2\n",
    "\n",
    "  wandb: # wandb config for run_handler, if \"wandb: null\" then logging to wandb is disabled for run_handler\n",
    "    init:\n",
    "      tags:\n",
    "        - ${config.experiment_data.experiment_tag}_exps\n",
    "        - run_handler\n",
    "      notes: #\n",
    "      group: ${config.experiment_data.experiment_tag}\n",
    "      job_type: run_handler\n",
    "\n",
    "seeds: [1,2]\n",
    "\n",
    "sweep:\n",
    "  type: grid\n",
    "  axes:\n",
    "    - parameter: data.dataset_kwargs.rotation_angle\n",
    "      vals: [0.0] #linspace(0,180,360,endpoint=True)\n",
    "\n",
    "start_num: 1 # use this to count how often this config is run\n",
    "\n",
    "###\n",
    "config:\n",
    "  experiment_data:\n",
    "    entity: jkuiml-fsl\n",
    "    project_name: sparsity\n",
    "    experiment_tag: \"11.5\"\n",
    "    experiment_type: startnum_${start_num}\n",
    "    experiment_name: mnist-${config.experiment_data.experiment_tag}.${start_num}-lenet\n",
    "    experiment_dir: null\n",
    "    experiment_notes: Different random inits for mode connectivity analysis.\n",
    "    job_name: null\n",
    "    seed: 0\n",
    "    hostname: null # the server on which the run is run, will be filled by run_handler\n",
    "    gpu_id: 5\n",
    "\n",
    "  wandb:\n",
    "    init:\n",
    "      tags: # list(), used to tag wandblogger\n",
    "        - ${config.experiment_data.experiment_tag}_exps\n",
    "      notes: ${config.experiment_data.experiment_notes} # str, used to make notes to wandblogger\n",
    "      group: ${config.experiment_data.experiment_tag} # null\n",
    "      job_type: ${config.experiment_data.experiment_type} # examples: hypsearch, pretrain, eval, etc.\n",
    "\n",
    "    watch:\n",
    "      log: null #parameters #null #all\n",
    "      log_freq: 5000\n",
    "\n",
    "  model:\n",
    "    name: fc\n",
    "    model_kwargs:\n",
    "      input_size: 784\n",
    "      hidden_sizes:\n",
    "        - 300\n",
    "        - 100\n",
    "      output_size: 10\n",
    "      flatten_input: True\n",
    "      dropout: null\n",
    "      act_fn: relu\n",
    "\n",
    "  trainer:\n",
    "    training_setup: supervised\n",
    "    n_steps: 2000\n",
    "    log_train_step_every: 1\n",
    "    log_additional_train_step_every_multiplier: 1\n",
    "    log_additional_logs: True\n",
    "    val_every: 5\n",
    "    save_every: 5\n",
    "    early_stopping_patience: 200\n",
    "    batch_size: 128\n",
    "    optimizer_scheduler:\n",
    "      optimizer_name: adamw #sgd #adamw\n",
    "      optimizer_kwargs:\n",
    "        lr: 0.001\n",
    "        weight_decay: 0.0\n",
    "    init_model: null\n",
    "\n",
    "    loss: crossentropy\n",
    "\n",
    "    metrics:\n",
    "      - Accuracy\n",
    "    num_workers: 4\n",
    "    verbose: False\n",
    "\n",
    "  data:\n",
    "    dataset: rotatedvision\n",
    "    dataset_kwargs:\n",
    "      data_root_path: /system/user/beck/pwbeck/data\n",
    "      dataset: mnist\n",
    "      rotation_angle: 0.0\n",
    "    dataset_split:\n",
    "      train_val_split: 0.8\n",
    "\n",
    "\"\"\"\n",
    "cfg2 = OmegaConf.create(config_yaml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp. Tag(start_num): 11.5(1)\n",
      "Exp. Name: mnist-11.5.1-lenet\n",
      "Training setup: supervised\n",
      "Model name: fc\n",
      "Dataset name: rotatedvision\n",
      "Sweep type: grid\n",
      "  data.dataset_kwargs.rotation_angle: [0.0]\n",
      "Num. jobs: 2\n",
      "Config updated: 2022-12-14 10:24:30\n",
      "Sweep started:  2022-12-14 10:26:23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sweepr2 = REPO.get_output_loader(cfg2)\n",
    "print(sweepr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 52.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweepr2.get_failed_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JobResult(mnist-11.5.1-lenet--rotation_angle-0-seed-1--221214_102651),\n",
       " JobResult(mnist-11.5.1-lenet--rotation_angle-0-seed-2--221214_102651)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_mnist = sweepr2.get_jobs()\n",
    "jobs_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = jobs_mnist[0].best_model\n",
    "model_B = jobs_mnist[1].best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cfg2 = cfg2.config.data\n",
    "ds_generator2 = DatasetGenerator(**data_cfg2)\n",
    "ds_generator2.generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interp. factors: 100%|██████████| 6/6 [00:22<00:00,  3.70s/it]\n",
      "{'__weights': [0.0,\n",
      "               0.20000000298023224,\n",
      "               0.4000000059604645,\n",
      "               0.6000000238418579,\n",
      "               0.800000011920929,\n",
      "               1.0],\n",
      " '_cosinesimilarity': 0.010202181525528431,\n",
      " '_l2distance': 30.355226516723633,\n",
      " 'val': [0.974958598613739,\n",
      "         0.9707711338996887,\n",
      "         0.8915689587593079,\n",
      "         0.9109537601470947,\n",
      "         0.9726828932762146,\n",
      "         0.976451575756073]}\n"
     ]
    }
   ],
   "source": [
    "res_dict = interpolate_linear(model_A, model_B, ds_generator2.train_split, score_fn, weights, {'val': ds_generator2.val_split}, dataloader_kwargs={'batch_size': 2048})\n",
    "pprint(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subspaces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac019f01eb2a0970f066d5e193a84f30bb43215eeeface9d3d8db32241c79700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
