defaults:
  - hydra: jobname_outputdir_format
  - _self_
#######

run_config: 
  exec_type: parallel # sequential
  hostname: dragonfly
  gpu_ids: [0]
  runs_per_gpu: 5
  
  wandb: # wandb config for run_handler, if "wandb: null" then logging to wandb is disabled for run_handler
    init:
      tags:
        - ${config.experiment_data.experiment_tag}_exps
        - run_handler
      notes: #
      group: ${config.experiment_data.experiment_tag}
      job_type: run_handler

seeds:
  - 0

sweep:
  type: grid
  axes:
    - parameter: trainer.batch_size
      vals: [1,5,10]
    - parameter: trainer.n_inner_iter
      vals: [3] #[3,5,10]

### 
config:
  experiment_data:
    entity: jkuiml-fsl # null
    project_name: erank_meta
    experiment_tag: 'DEBUG'
    experiment_name: sinus-${config.experiment_data.experiment_tag}-reptile_initial_exps-batch_size_${config.trainer.batch_size}-n_inner_iter_${config.trainer.n_inner_iter}
    experiment_dir: null
    seed: 0
    hostname: null # the server on which the run is run, will be filled by run_handler
    gpu_id: 0

  wandb:
    init:
      tags: # list(), used to tag wandblogger
        - ${config.experiment_data.experiment_tag}_exps
        - erank
      notes: Hyperparametersearch for own Reptile implementation # str, used to make notes to wandblogger
      group: ${config.experiment_data.experiment_tag} # null 
      job_type: hypsearch0 # examples: hypsearch, pretrain, eval, etc. 
          
    watch:
      log: null #parameters #null #all
      log_freq: 5000

  model:
    name: fc
    model_kwargs:
      input_size: 1
      hidden_sizes:
        - 64
        - 64
      output_size: 1
      flatten_input: true # can probably use also false
      dropout: null
      act_fn: relu

  trainer:
    training_setup: reptile
    n_epochs: 100000 # number of iterations (outer/meta gradient steps)
    val_every: 1000
    save_every: 10000
    early_stopping_patience: null # no early stopping
    batch_size: XXX #1 #5 # meta-batch size (number of tasks sampled per iteration)
    optimizer_scheduler:
      optimizer_name: sgd #adamw # TODO implement optimizer state sharing between inner loops
      optimizer_kwargs:
        lr: 0.001
        weight_decay: 0.0 #0.001
    init_model: null
    inner_optimizer: 
      optimizer_name: sgd
      optimizer_kwargs:
        lr: 0.01
    n_inner_iter: XXX #3
    val_plots: 1 # Prediction plots for `val_plots` tasks. If int: Uses the first `val_plots` tasks to generate plots

    loss: mse
    # erank:
    #   type: none #pretraindiff #none #random #pretraindiff
    #   loss_weight: XXX
    #   dir_buffer: null
    #   buffer_size: 10 # number of directions stored in the buffer
    #   norm_directions: False
    #   use_abs_model_params: True
    num_workers: 4

  data: 
    metadataset: sinus
    train_metadataset_kwargs:
      support_size: 10
      query_size: 50
      num_tasks: 10000
      amplitude_range: [0.1, 5.0]
      phase_range: [0, 6.283185307]
      x_range: [-5, 5]
      regenerate_task_support_set: False
    val_metadataset_kwargs:
      support_size: 10
      query_size: 50
      num_tasks: 1000
      amplitude_range: [0.1, 5.0]
      phase_range: [0, 6.283185307]
      x_range: [-5, 5]
      regenerate_task_support_set: False
    