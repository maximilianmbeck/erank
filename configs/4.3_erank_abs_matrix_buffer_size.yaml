### HYDRA START
hydra:
  run:
    dir: outputs/${hydra.job.name}
  sweep:
    dir: outputs/${hydra.job.name}
    subdir: ${hydra.job.num}
  job:
    chdir: True # change working directory of run
    name: ${config.experiment_data.experiment_name}_${now:%d%m%y_%H%M%S}
### HYDRA END

run_config: # eagle_02, gorilla_234
  exec_type: parallel # sequential
  gpu_ids: [2, 3, 4]
  runs_per_gpu: 4

seeds:
  - 0

sweep:
  type: grid
  axes:
    - parameter: trainer.erank.loss_weight
      vals: [0.1, 1.0, 10, 100, 500, 1000] # [0.0]
    - parameter: trainer.optimizer_scheduler.optimizer_kwargs.weight_decay
      vals: [0.0, 0.001]
    - parameter: trainer.erank.buffer_size
      vals: [1, 3, 5, 10] #[15, 20, 25, 30]
    - parameter: data.train_task_idx
      vals: [30, 31, 32]
###
config:
  experiment_data:
    project_name: erank_supervised
    experiment_tag: "4.3"
    experiment_name: f_mnist-${config.experiment_data.experiment_tag}-num_dir_sweep-buffer_size_${config.trainer.erank.buffer_size}-weight_decay_${config.trainer.optimizer_scheduler.optimizer_kwargs.weight_decay}-erankweight_${config.trainer.erank.loss_weight}-taskidx_${config.data.train_task_idx}
    experiment_dir: null
    seed: 0
    gpu_id: 2

  tags: # list(), used to tag wandblogger
    - erank
    - ${config.experiment_data.experiment_tag}_exps
  notes: Sweep over buffer size / number of directions in matrix. Training with erank regularization. Use abs model parameters for directions. Train long and apply weight decay. # str, used to make notes to wandblogger

  model:
    name: fc
    model_kwargs:
      input_size: 784
      hidden_sizes:
        - 512
        - 512
      output_size: 10
      flatten_input: true
      dropout: 0.2
      act_fn: relu

  trainer:
    n_epochs: 300
    val_every: 1
    save_every: 50
    early_stopping_patience: 200
    batch_size: 256
    optimizer_scheduler:
      optimizer_name: adam
      optimizer_kwargs:
        lr: 0.001
        weight_decay: XXX
    init_model: /system/user/beck/pwbeck/projects/regularization/erank/res/init_model.p
    loss: crossentropy
    erank:
      type: pretraindiff
      loss_weight: XXX
      dir_buffer: /system/user/beck/pwbeck/projects/regularization/erank/outputs/f_mnist-4.2-pretrain30-taskidx_XXX_070722_155505/outputs
      buffer_size: XXX # number of directions stored in the buffer
      norm_directions: False
      use_abs_model_params: True
    num_workers: 4

  data:
    dataset: fashion_mnist
    dataset_dir: /system/user/beck/pwbeck/data/mnist
    train_val_split: 0.8
    num_train_tasks: 13
    subsplit_first_n_train_tasks: 10
    num_subsplit_tasks: 30
    train_task_idx: XXX

    normalizer: # mean and std per channel
      mean:
        - 0.2860
      std:
        - 0.3205
