defaults:
  - hydra: jobname_outputdir_format
#######

run_config: 
  exec_type: parallel # sequential
  gpu_ids: [3]
  runs_per_gpu: 9

seeds: null

sweep:
  type: line
  axes:
    - parameter: experiment_data.seed
      vals: [0,1,2,3,4,5,6,7,8,9]
    - parameter: data.train_task_idx
      vals: [0,1,2,3,4,5,6,7,8,9] 
### 
config:
  experiment_data:
    entity: null # jkuiml-fsl
    project_name: erank_supervised
    experiment_tag: '5.19'
    experiment_name: f_mnist-${config.experiment_data.experiment_tag}-fc_pretrain_different_inits-taskidx_${config.data.dataset_split.train_task_idx}
    experiment_dir: null
    seed: 0
    gpu_id: 2

  wandb:
    init:
      tags: # list(), used to tag wandblogger
        - ${config.experiment_data.experiment_tag}_exps
        - erank
        - absmodel
      notes: # str, used to make notes to wandblogger
      group: ${config.experiment_data.experiment_tag} # null 
      job_type: pretrain # examples: hypsearch, pretrain, eval, etc. 
          
    watch:
      log: parameters #null #all
      log_freq: 5000

  model:
    name: fc
    model_kwargs:
      input_size: 784
      hidden_sizes:
        - 512
        - 512
      output_size: 10
      flatten_input: true
      dropout: 0.2
      act_fn: relu

  trainer:
    n_epochs: 50
    val_every: 1
    save_every: 100
    early_stopping_patience: 10
    batch_size: 256
    optimizer_scheduler:
      optimizer_name: adamw
      optimizer_kwargs:
        lr: 0.001
        weight_decay: 0.0 #0.001
    init_model: null
    loss: crossentropy
    erank:
      type: none #pretraindiff #none #random #pretraindiff
      loss_weight: XXX
      dir_buffer: null
      buffer_size: 10 # number of directions stored in the buffer
      norm_directions: False
      use_abs_model_params: True
    num_workers: 4

  data: 
    dataset: fashion_mnist
    dataset_kwargs:
      dataset_dir: /system/user/beck/pwbeck/data/mnist
    dataset_split:
      train_val_split: 0.8
      num_train_tasks: 13
      subsplit_first_n_train_tasks: 0
      num_subsplit_tasks: 0
      train_task_idx: XXX